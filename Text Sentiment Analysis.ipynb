{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text Sentiment Analysis (using scikit-learn and NLTK):"
      ],
      "metadata": {
        "id": "idW5Cqnu_VAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the libraries\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import nltk\n",
        "from nltk.corpus import movie_reviews"
      ],
      "metadata": {
        "id": "No7VZVbW_iq1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources\n",
        "nltk.download(\"movie_reviews\")\n",
        "\n",
        "# Prepare data\n",
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "np.random.shuffle(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuOX1Wt1_98H",
        "outputId": "cd3ed13f-67d9-4f20-d36d-3934181252f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "train_documents, test_documents = train_test_split(documents, test_size=0.2, random_state=42)\n",
        "train_words = [\" \".join(doc) for doc, category in train_documents]\n",
        "test_words = [\" \".join(doc) for doc, category in test_documents]\n",
        "y_train = [category for doc, category in train_documents]\n",
        "y_test = [category for doc, category in test_documents]"
      ],
      "metadata": {
        "id": "oHZYlG7-AHq1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert words to features using Bag-of-Words\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_words)\n",
        "X_test = vectorizer.transform(test_words)"
      ],
      "metadata": {
        "id": "g5UqATmvAIfn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and train Naive Bayes classifier\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "5OllemX4AIob"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oq9_aCYfLsN",
        "outputId": "ef8a5823-07cc-42e1-a470-4e8a53ec1c58"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.81\n"
          ]
        }
      ]
    }
  ]
}